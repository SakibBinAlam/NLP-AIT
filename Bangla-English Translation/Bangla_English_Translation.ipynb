{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata"
      ],
      "metadata": {
        "id": "va_Eoqp58rJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db9598b1-46bf-4347-98be-78fd60afac82"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.13.1+cu116)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.26.14)\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchdata) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2022.12.7)\n",
            "Installing collected packages: portalocker, torchdata\n",
            "Successfully installed portalocker-2.7.0 torchdata-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D83oKtlMuyj0",
        "outputId": "07c196ab-d719-4a7d-c6e4-327d2f8a56dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download xx_ent_wiki_sm  ## bangla tokenizer"
      ],
      "metadata": {
        "id": "MkM-KCIJ-qxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e923f830-534a-4284-9857-4da91dbb988b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-05 13:32:46.304707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-05 13:32:47.156359: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-05 13:32:47.156466: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-05 13:32:47.156486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xx-ent-wiki-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-3.4.0/xx_ent_wiki_sm-3.4.0-py3-none-any.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from xx-ent-wiki-sm==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (3.1.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (8.1.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (1.22.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (2.25.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (2.4.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (1.10.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (23.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->xx-ent-wiki-sm==3.4.0) (2.1.2)\n",
            "Installing collected packages: xx-ent-wiki-sm\n",
            "Successfully installed xx-ent-wiki-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('xx_ent_wiki_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchdata, torchtext\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random, math, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7n4izr_BTri",
        "outputId": "0a157e01-8673-473b-ce40-5921ddb3e4d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "C2qJ9PtJBX6z",
        "outputId": "53f67d43-e99f-4cac-a895-7e5f74922e73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AYT_zVR_8moU",
        "outputId": "65064734-7adf-45f2-a722-895940dc4609"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchtext.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2jt0W6lR9AMS",
        "outputId": "ea694b7a-1968-4b20-ce6e-4ecf5b881b88"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.14.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. ETL: Loading the Dataset"
      ],
      "metadata": {
        "id": "vMFeAQhD9DvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment this if you are not using our department puffer\n",
        "# import os\n",
        "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
        "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
        "\n",
        "# path = \"/content/ben.txt\"\n",
        "\n",
        "path = open(\"/content/drive/MyDrive/Colab Notebooks/NLP/data/eng-ban.txt\", encoding='UTF-8').read().strip().split('\\n')  \n",
        "\n",
        "def load_data(path):\n",
        "  #ext = path.read_text(encoding='utf-8')\n",
        "  with open(path, \"r\", encoding=\"utf8\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "  lines = text.splitlines()\n",
        "  pairs = [line.split('\\t') for line in lines]\n",
        "\n",
        "  context = np.array([context for target, context, _ in pairs])\n",
        "  target = np.array([target for target, context, _ in pairs])\n",
        "\n",
        "  return target, context"
      ],
      "metadata": {
        "id": "KlLlP54Z9GKE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_pairs = [[w for w in l.split('\\t')] for l in path]\n",
        "word_pairs[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7YbClaaa-0W",
        "outputId": "74bbe7ac-c251-4df5-ea9a-b40a1b54fd9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Attack!',\n",
              " 'আক্রমণ!',\n",
              " 'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #5489253 (tanay)']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(word_pairs, columns=[\"en\", \"bn\", \"extra\"])"
      ],
      "metadata": {
        "id": "CjoPkxG_bJD7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the third column \n",
        "data = data.drop(\"extra\", axis=1)"
      ],
      "metadata": {
        "id": "i29ksGqmRQO9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[50:55]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6YkuSu8yRQDK",
        "outputId": "69666a9e-cddc-4aef-fba4-fd16f5749036"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          en              bn\n",
              "50  Call me.    আমাকে ডাকিস।\n",
              "51  Call us.    আমাদের ডেকো।\n",
              "52  Call us.   আমাদের ডাকিস।\n",
              "53  Call us.  আমাদের ডাকবেন।\n",
              "54  Come in.     ভেতরে আসুন।"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68f933ca-36c7-47bd-a311-5388bee07e97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>bn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Call me.</td>\n",
              "      <td>আমাকে ডাকিস।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Call us.</td>\n",
              "      <td>আমাদের ডেকো।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Call us.</td>\n",
              "      <td>আমাদের ডাকিস।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Call us.</td>\n",
              "      <td>আমাদের ডাকবেন।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Come in.</td>\n",
              "      <td>ভেতরে আসুন।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68f933ca-36c7-47bd-a311-5388bee07e97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68f933ca-36c7-47bd-a311-5388bee07e97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68f933ca-36c7-47bd-a311-5388bee07e97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_titles = [\"bn\",\"en\"]\n",
        "data = data.reindex(columns=columns_titles)"
      ],
      "metadata": {
        "id": "3iLjbeTN4NL5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QyL32GVq4Y-S",
        "outputId": "91d90cfb-d67a-40b9-b689-aa0193ed5233"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       bn    en\n",
              "0    যাও।   Go.\n",
              "1    যান।   Go.\n",
              "2     যা।   Go.\n",
              "3  পালাও!  Run!\n",
              "4  পালান!  Run!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6992cf49-c0a1-44e8-8d96-f4ff0ec5e6b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bn</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>যাও।</td>\n",
              "      <td>Go.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>যান।</td>\n",
              "      <td>Go.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>যা।</td>\n",
              "      <td>Go.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>পালাও!</td>\n",
              "      <td>Run!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>পালান!</td>\n",
              "      <td>Run!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6992cf49-c0a1-44e8-8d96-f4ff0ec5e6b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6992cf49-c0a1-44e8-8d96-f4ff0ec5e6b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6992cf49-c0a1-44e8-8d96-f4ff0ec5e6b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = data.values.tolist()"
      ],
      "metadata": {
        "id": "nd-NheYbvlrO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. EDA"
      ],
      "metadata": {
        "id": "Zkk3-wsp-F6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = len(dataset)\n",
        "dataset_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hli-3hZ4F1u-",
        "outputId": "74e84447-6ad9-43c8-f575-704c6255a64a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5514"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split\n",
        "\n",
        "random.shuffle(dataset)\n",
        "train_data_set_size = int(dataset_size *0.8)\n",
        "\n",
        "train_dataset = dataset[:train_data_set_size]\n",
        "test = dataset[train_data_set_size:]\n",
        "\n",
        "train_size = int(train_data_set_size *0.8)\n",
        "train = train_dataset[:train_size]\n",
        "val = train_dataset[train_size:]"
      ],
      "metadata": {
        "id": "hQW_tDbyFKMU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert sum((len(train),len(val),len(test))) == dataset_size"
      ],
      "metadata": {
        "id": "W9NDscClwALb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preprocessing"
      ],
      "metadata": {
        "id": "-9A0xcTj-Zc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing"
      ],
      "metadata": {
        "id": "4ztmkNsv-cLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ],
      "metadata": {
        "id": "P6xCt3gD-gX_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "SRC_LANGUAGE = 'bn'\n",
        "TRG_LANGUAGE = 'en'\n",
        "\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='xx_ent_wiki_sm')\n",
        "token_transform[TRG_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')"
      ],
      "metadata": {
        "id": "_Sdpe5pZ-4aO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization for bangla\n",
        "print(\"Sentence: \", train[0][0])\n",
        "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](train[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex_ugkxxxSHy",
        "outputId": "9905b85d-84cf-43bb-8a9a-ee6ae6092921"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  আমি আপনাকে অবাক করার চেষ্টা ছেড়ে দিয়েছি।\n",
            "Tokenization:  ['আমি', 'আপনাকে', 'অবাক', 'করার', 'চেষ্টা', 'ছেড়ে', 'দিয়েছি', '।']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization for english\n",
        "print(\"Sentence: \", train[0][1])\n",
        "print(\"Tokenization: \", token_transform[TRG_LANGUAGE](train[0][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc2w0In3-4UK",
        "outputId": "db7da2bb-783a-484b-cdfa-5e599bcb4372"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  I've given up on trying to surprise you.\n",
            "Tokenization:  ['I', \"'ve\", 'given', 'up', 'on', 'trying', 'to', 'surprise', 'you', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to yield list of tokens\n",
        "# here data can be `train` or `val` or `test`\n",
        "def yield_tokens(data, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data:\n",
        "        yield token_transform[language](data_sample[language_index[language]]) # either first or second index"
      ],
      "metadata": {
        "id": "7kF57BkA-4KC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining special symbols and indices\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# making sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
      ],
      "metadata": {
        "id": "Xi0XWgtz_MCh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text to Integers (Numericalization)"
      ],
      "metadata": {
        "id": "nXXTmuMa_Yek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    # creating torchtext's Vocab object \n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln), \n",
        "                                                    min_freq=2,   # if not, everything will be treated as UNK\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True) # indicates whether to insert symbols at the beginning or at the end                                            \n",
        "# Setting UNK_IDX as the default index. This index is returned when the token is not found. \n",
        "# If not, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "IPuli2_MzJE0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('vocab_transform.pickle', 'wb') as f:\n",
        "    pickle.dump(vocab_transform, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "N4jRC6JpSxtj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking some examples\n",
        "vocab_transform[TRG_LANGUAGE](['I', 'love', 'programming'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCxEWXM4_Lzt",
        "outputId": "fec113de-ada7-430a-e515-a806880c5fe0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 242, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can reverse it....\n",
        "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
        "\n",
        "# printing 100, for example\n",
        "mapping[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EaX6rHG3BVpd",
        "outputId": "cda9e8e9-3eb6-4841-87c7-7ba562de641a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'নাম'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try unknown vocab\n",
        "mapping[0]\n",
        "# they will all map to <unk> which has 0 as integer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bxA-ZZG9BVkY",
        "outputId": "dbde3c75-95fd-4e53-c38d-7790ee7b504a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try special symbols\n",
        "mapping[1], mapping[2], mapping[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-mTZtDCBVdb",
        "outputId": "cb598393-e14b-4dad-b5d9-102a926fb772"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<pad>', '<sos>', '<eos>')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking unique vocabularies\n",
        "len(mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oSzGIJ8BmDw",
        "outputId": "1f6f0ec3-c439-4e63-ee98-fc1268c95fae"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1391"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Preparing the DataLoader"
      ],
      "metadata": {
        "id": "ysAZjge4B9i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([SOS_IDX]), \n",
        "                      torch.tensor(token_ids), \n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and trg language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_batch(batch):\n",
        "    src_batch, src_len_batch, trg_batch = [], [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(processed_text)\n",
        "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
        "        src_len_batch.append(processed_text.size(0))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
      ],
      "metadata": {
        "id": "DUoBi0jmBl5i"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(val, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_loader  = DataLoader(test, batch_size=batch_size,\n",
        "                             shuffle=True, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "xnrCD2lPCHhx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for bn, _, en in train_loader:\n",
        "    break"
      ],
      "metadata": {
        "id": "A7SjeyFbCKaT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"English shape: \", en.shape)  # (seq len, batch_size)\n",
        "print(\"Bengali shape: \", bn.shape)   # (seq len, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaF3g_3oCKTw",
        "outputId": "b086e482-f2c2-49d8-8de9-e878e0f0d078"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English shape:  torch.Size([11, 64])\n",
            "Bengali shape:  torch.Size([11, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Designing the Model"
      ],
      "metadata": {
        "id": "I53_aEYwCQ6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "At0aig1nCeXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, bidirectional = True)\n",
        "        self.fc = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        # src = [src len, batch size]\n",
        "        # src_len = [batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded = [src len, batch size, emb dim]\n",
        "                \n",
        "        # need to explicitly put lengths on cpu!\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'), enforce_sorted=False)\n",
        "                \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)        \n",
        "        # packed_outputs is a packed sequence containing all hidden states\n",
        "        # hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "        # outputs is now a non-packed sequence, all hidden states obtained\n",
        "        # when the input is a pad token are all zeros\n",
        "            \n",
        "        # outputs = [src len, batch size, hid dim * num directions]\n",
        "        # hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        # hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        # outputs are always from the last layer\n",
        "        \n",
        "        # hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        # hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        # initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        # encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        # outputs = [src len, batch size, hid dim * 2]\n",
        "        # hidden = [batch size, hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "5M3FkFfCCVoz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ],
      "metadata": {
        "id": "aN6ZFkI2C1Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class Attention(nn.Module):\n",
        "#     def __init__(self, hid_dim, variants):\n",
        "#         super().__init__()\n",
        "        \n",
        "#         self.v = nn.Linear(hid_dim, 1, bias = False)\n",
        "#         self.W = nn.Linear(hid_dim,     hid_dim) # for decoder\n",
        "#         self.U = nn.Linear(hid_dim * 2, hid_dim) # for encoder outputs\n",
        "                \n",
        "#     def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "#         # hidden = [batch size, hid dim]\n",
        "#         # encoder_outputs = [src len, batch size, hid dim * 2]\n",
        "        \n",
        "#         batch_size = encoder_outputs.shape[1]\n",
        "#         src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "#         # repeat decoder hidden state src_len times\n",
        "#         hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "#         # hidden = [batch size, src len, hid dim]\n",
        "\n",
        "#         encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "#         # encoder_outputs = [batch size, src len, hid dim * 2]\n",
        "        \n",
        "#         energy = torch.tanh(self.W(hidden) + self.U(encoder_outputs))\n",
        "#         # energy = [batch size, src len, hid dim]\n",
        "        \n",
        "#         attention = self.v(energy).squeeze(2)\n",
        "#         # attention = [batch size, src len]\n",
        "        \n",
        "#         # use masked_fill_ if you want in-place\n",
        "#         attention = attention.masked_fill(mask, -1e10)\n",
        "        \n",
        "#         return F.softmax(attention, dim = 1)"
      ],
      "metadata": {
        "id": "SJFP44CQCWV8"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim, variants):\n",
        "        super().__init__()\n",
        "        self.variants = variants\n",
        "        self.v = nn.Linear(hid_dim, 1, bias = False)\n",
        "        self.W = nn.Linear(hid_dim,     hid_dim) #for decoder\n",
        "        self.U = nn.Linear(hid_dim * 2, hid_dim) #for encoder outputs\n",
        "                \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #hidden = [batch size, hid dim]\n",
        "        #encoder_outputs = [src len, batch size, hid dim * 2]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        #encoder_outputs = [batch size, src len, hid dim * 2]\n",
        "\n",
        "        if self.variants == 'additive': #work\n",
        "            #repeat decoder hidden state src_len times\n",
        "            hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "            #hidden = [batch size, src len, hid dim]\n",
        "            \n",
        "            energy = torch.tanh(self.W(hidden) + self.U(encoder_outputs))\n",
        "            #energy = [batch size, src len, hid dim]\n",
        "            \n",
        "            attention = self.v(energy).squeeze(2)\n",
        "            #attention = [batch size, src len]\n",
        "\n",
        "            #use masked_fill_ if you want in-place\n",
        "            attention = attention.masked_fill(mask, -1e10)\n",
        "            \n",
        "        elif self.variants == 'general': #work\n",
        "            hidden = hidden.unsqueeze(1).repeat(1, 1, 2)\n",
        "            #hidden = [batch size, 1, hid dim*2]\n",
        "            #encoder_outputs = [batch size, hid dim * 2, src len]\n",
        "\n",
        "            energy = torch.bmm(hidden, encoder_outputs.transpose(1, 2))\n",
        "            attention = energy.squeeze(1)\n",
        "            #attention = [batch size, src len]\n",
        "\n",
        "        elif self.variants == 'multiplicative':\n",
        "            wh = self.W(hidden).unsqueeze(1).repeat(1, 1, 2)\n",
        "            #wh = [batch size, 1, hid dim*2]\n",
        "            #encoder_outputs = [batch size, hid dim * 2, src len]\n",
        "\n",
        "            energy = torch.bmm(wh, encoder_outputs.transpose(1, 2))\n",
        "            attention = energy.squeeze(1)\n",
        "\n",
        "        #attention = [batch size, src len]\n",
        "        return F.softmax(attention, dim = 1)"
      ],
      "metadata": {
        "id": "YjTHdQF7EmT0"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of masked_fill\n",
        "# reall that 1 is pad_idx\n",
        "x = torch.tensor([ [9, 1, 7, 2, 1, 1], [99, 1, 1, 0, 8, 9] ])\n",
        "\n",
        "mask = (x == PAD_IDX)\n",
        "\n",
        "x.masked_fill_(mask, -1e10)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfjUwGlJCWJ9",
        "outputId": "c94c6db3-fdad-4b11-b89e-cbd8f5873881"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[           9, -10000000000,            7,            2, -10000000000,\n",
            "         -10000000000],\n",
            "        [          99, -10000000000, -10000000000,            0,            8,\n",
            "                    9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "igecHGQUDR2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.gru = nn.GRU((hid_dim * 2) + emb_dim, hid_dim)\n",
        "        self.fc = nn.Linear((hid_dim * 2) + hid_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "                \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "             \n",
        "        # input = [batch size]\n",
        "        # hidden = [batch size, hid dim]\n",
        "        # encoder_outputs = [src len, batch size, hid dim * 2]\n",
        "        # mask = [batch size, src len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        # input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "        # a = [batch size, src len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        # a = [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # encoder_outputs = [batch size, src len, hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        # weighted = [batch size, 1, hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        # weighted = [1, batch size, hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        # rnn_input = [1, batch size, (hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n",
        "        # output = [seq len, batch size, dec hid dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        # output = [1, batch size, hid dim]\n",
        "        # hidden = [1, batch size, hid dim]\n",
        "        # this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "               \n",
        "        prediction = self.fc(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        # prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "metadata": {
        "id": "QOV3NKUXDTXA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting them together (become Seq2Seq!)"
      ],
      "metadata": {
        "id": "j4Lz665DDrue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqPackedAttention(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src == self.src_pad_idx).permute(1, 0)  # permute so it's the same shape as attention\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        # src = [src len, batch size]\n",
        "        # src_len = [batch size]\n",
        "        # trg = [trg len, batch size]\n",
        "        # teacher_forcing_ratio is probability to use teacher forcing\n",
        "        # e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "                    \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "                \n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        # tensor to store attentiont outputs from decoder\n",
        "        attentions = torch.zeros(trg_len, batch_size, src.shape[0]).to(self.device)\n",
        "        \n",
        "        # encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        # hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        # first input to the decoder is the <sos> tokens\n",
        "        input_ = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "        # mask = [batch size, src len]\n",
        "                \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            # insert input token embedding, previous hidden state, all encoder hidden states and mask\n",
        "            # receive output tensor (predictions) and new hidden state\n",
        "            output, hidden, attention = self.decoder(input_, hidden, encoder_outputs, mask)\n",
        "            # output    = [batch size, output dim]\n",
        "            # hidden    = [batch size, hid dim]\n",
        "            # attention = [batch size, src len]\n",
        "            \n",
        "            # place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            # place attentions in a tensor holding attention for each token\n",
        "            attentions[t] = attention\n",
        "            \n",
        "            # decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            # get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            # if teacher forcing, use actual next token as next input\n",
        "            # if not, use predicted token\n",
        "            input_ = trg[t] if teacher_force else top1\n",
        "            \n",
        "        return outputs, attentions"
      ],
      "metadata": {
        "id": "fDkVLxsVDlKZ"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Training"
      ],
      "metadata": {
        "id": "hDPgheTvEA4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)"
      ],
      "metadata": {
        "id": "gi9UBefoDk9n"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 General Attention"
      ],
      "metadata": {
        "id": "CtGEsnKf1wI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "emb_dim     = 256  \n",
        "hid_dim     = 512  \n",
        "dropout     = 0.5\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "\n",
        "attn = Attention(hid_dim, variants = 'general')\n",
        "enc  = Encoder(input_dim,  emb_dim,  hid_dim, dropout)\n",
        "dec  = Decoder(output_dim, emb_dim,  hid_dim, dropout, attn)\n",
        "\n",
        "model = Seq2SeqPackedAttention(enc, dec, SRC_PAD_IDX, device).to(device)\n",
        "model.apply(initialize_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhvqCAfxDk2H",
        "outputId": "cc6787b3-56e1-42d1-bc2a-0bb594029f77"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqPackedAttention(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(1391, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "      (W): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (U): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(1130, 256)\n",
              "    (gru): GRU(1280, 512)\n",
              "    (fc): Linear(in_features=1792, out_features=1130, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can print the complexity by the number of parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "    \n",
        "count_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qeDTbzUERGs",
        "outputId": "96068a69-2479-4cb7-f101-8c29b02b4067"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "356096\n",
            "393216\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "393216\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "524288\n",
            "   512\n",
            "   512\n",
            "262144\n",
            "   512\n",
            "524288\n",
            "   512\n",
            "289280\n",
            "1966080\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "2024960\n",
            "  1130\n",
            "______\n",
            "9105258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "# training hyperparameters\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX) # combining softmax with cross entropy"
      ],
      "metadata": {
        "id": "gf6Mn_rXEQ_G"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for src, src_length, trg in loader:\n",
        "        \n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, attentions = model(src, src_length, trg)\n",
        "        \n",
        "        # trg    = [trg len, batch size]\n",
        "        # output = [trg len, batch size, output dim]\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        # the loss function only works on 2d inputs with 1d targets thus we need to flatten each of them\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg    = trg[1:].view(-1)\n",
        "        # trg    = [(trg len - 1) * batch size]\n",
        "        # output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        # clipping the gradients to prevent them from exploding (a common issue in RNNs)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ],
      "metadata": {
        "id": "F_Jij516EhI-"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, criterion, loader_length):\n",
        "        \n",
        "    # turning off dropout (and batch norm if used)\n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for src, src_length, trg in loader:\n",
        "        \n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, attentions = model(src, src_length, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            # trg    = [trg len, batch size]\n",
        "            # output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            # trg    = [(trg len - 1) * batch size]\n",
        "            # output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ],
      "metadata": {
        "id": "KFi2kG8bEhBt"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting everything together"
      ],
      "metadata": {
        "id": "NMbytN0nFEt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_length = len(list(iter(train_loader)))\n",
        "val_loader_length   = len(list(iter(valid_loader)))\n",
        "test_loader_length  = len(list(iter(test_loader)))"
      ],
      "metadata": {
        "id": "WMzIeSvQEg7B"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "kon0DQ62FNLV"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "num_epochs = 10\n",
        "clip       = 1\n",
        "\n",
        "save_path = f'{model.__class__.__name__}.pt'\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
        "    \n",
        "    # for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "    \n",
        "    # lower perplexity is better"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soLFluPUFNAp",
        "outputId": "de34265e-a57e-4c9d-d74c-c3aae222b8dd"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 4s\n",
            "\tTrain Loss: 5.006 | Train PPL: 149.289\n",
            "\t Val. Loss: 4.224 |  Val. PPL:  68.335\n",
            "Epoch: 02 | Time: 0m 2s\n",
            "\tTrain Loss: 4.099 | Train PPL:  60.299\n",
            "\t Val. Loss: 3.944 |  Val. PPL:  51.648\n",
            "Epoch: 03 | Time: 0m 2s\n",
            "\tTrain Loss: 3.718 | Train PPL:  41.202\n",
            "\t Val. Loss: 3.778 |  Val. PPL:  43.711\n",
            "Epoch: 04 | Time: 0m 3s\n",
            "\tTrain Loss: 3.420 | Train PPL:  30.573\n",
            "\t Val. Loss: 3.660 |  Val. PPL:  38.863\n",
            "Epoch: 05 | Time: 0m 3s\n",
            "\tTrain Loss: 3.196 | Train PPL:  24.440\n",
            "\t Val. Loss: 3.469 |  Val. PPL:  32.105\n",
            "Epoch: 06 | Time: 0m 2s\n",
            "\tTrain Loss: 2.937 | Train PPL:  18.864\n",
            "\t Val. Loss: 3.378 |  Val. PPL:  29.309\n",
            "Epoch: 07 | Time: 0m 2s\n",
            "\tTrain Loss: 2.735 | Train PPL:  15.415\n",
            "\t Val. Loss: 3.309 |  Val. PPL:  27.369\n",
            "Epoch: 08 | Time: 0m 3s\n",
            "\tTrain Loss: 2.543 | Train PPL:  12.719\n",
            "\t Val. Loss: 3.271 |  Val. PPL:  26.337\n",
            "Epoch: 09 | Time: 0m 3s\n",
            "\tTrain Loss: 2.375 | Train PPL:  10.751\n",
            "\t Val. Loss: 3.140 |  Val. PPL:  23.093\n",
            "Epoch: 10 | Time: 0m 2s\n",
            "\tTrain Loss: 2.216 | Train PPL:   9.175\n",
            "\t Val. Loss: 3.041 |  Val. PPL:  20.919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(valid_losses, label = 'valid loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "ikmcUy0mFM0c",
        "outputId": "359dbfef-3b76-4b7d-da07-29d9690d4c81"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoniPsJoOI2j",
        "outputId": "656bbca8-09fa-43fe-8e65-f520a107e357"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 3.046 | Test PPL:  21.025 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "Qyv3YqZRONiB"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Multiplicative Attention"
      ],
      "metadata": {
        "id": "3FDxsWVn7379"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "emb_dim     = 256  \n",
        "hid_dim     = 512  \n",
        "dropout     = 0.5\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "\n",
        "attn = Attention(hid_dim, variants = 'multiplicative')\n",
        "enc  = Encoder(input_dim,  emb_dim,  hid_dim, dropout)\n",
        "dec  = Decoder(output_dim, emb_dim,  hid_dim, dropout, attn)\n",
        "\n",
        "mul_model = Seq2SeqPackedAttention(enc, dec, SRC_PAD_IDX, device).to(device)\n",
        "mul_model.apply(initialize_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkPoTlOf78I5",
        "outputId": "3f3708fa-7a5c-4212-af79-902dc52088c4"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqPackedAttention(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(1391, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "      (W): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (U): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(1130, 256)\n",
              "    (gru): GRU(1280, 512)\n",
              "    (fc): Linear(in_features=1792, out_features=1130, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can print the complexity by the number of parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in mul_model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "    \n",
        "count_parameters(mul_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-kD0Lfn78kw",
        "outputId": "16d73066-e4bd-4af6-d167-b796f314ad33"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "356096\n",
            "393216\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "393216\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "524288\n",
            "   512\n",
            "   512\n",
            "262144\n",
            "   512\n",
            "524288\n",
            "   512\n",
            "289280\n",
            "1966080\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "2024960\n",
            "  1130\n",
            "______\n",
            "9105258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "# training hyperparameters\n",
        "optimizer = optim.Adam(mul_model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX) # combining softmax with cross entropy"
      ],
      "metadata": {
        "id": "W64_KDEb8U9V"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for src, src_length, trg in loader:\n",
        "        \n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, attentions = model(src, src_length, trg)\n",
        "        \n",
        "        # trg    = [trg len, batch size]\n",
        "        # output = [trg len, batch size, output dim]\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        # the loss function only works on 2d inputs with 1d targets thus we need to flatten each of them\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg    = trg[1:].view(-1)\n",
        "        # trg    = [(trg len - 1) * batch size]\n",
        "        # output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        # clipping the gradients to prevent them from exploding (a common issue in RNNs)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ],
      "metadata": {
        "id": "PZOaYEL18tJP"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, criterion, loader_length):\n",
        "        \n",
        "    # turning off dropout (and batch norm if used)\n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for src, src_length, trg in loader:\n",
        "        \n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, attentions = model(src, src_length, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            # trg    = [trg len, batch size]\n",
        "            # output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            # trg    = [(trg len - 1) * batch size]\n",
        "            # output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ],
      "metadata": {
        "id": "JZk8cQKl8z9Q"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting everything together"
      ],
      "metadata": {
        "id": "wQIBLLj587Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_length = len(list(iter(train_loader)))\n",
        "val_loader_length   = len(list(iter(valid_loader)))\n",
        "test_loader_length  = len(list(iter(test_loader)))"
      ],
      "metadata": {
        "id": "Pw4qZOLH8Uu7"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "2Mse2o0T8Up4"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "num_epochs = 10\n",
        "clip       = 1\n",
        "\n",
        "save_path = f'{mul_model.__class__.__name__}.pt'\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(mul_model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    valid_loss = evaluate(mul_model, valid_loader, criterion, val_loader_length)\n",
        "    \n",
        "    # for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(mul_model.state_dict(), save_path)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "    \n",
        "    # lower perplexity is better"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d2e01a-8939-455f-af89-28388f216b3c",
        "id": "fw6uKsV-9cfd"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 3s\n",
            "\tTrain Loss: 5.075 | Train PPL: 159.973\n",
            "\t Val. Loss: 4.234 |  Val. PPL:  68.959\n",
            "Epoch: 02 | Time: 0m 3s\n",
            "\tTrain Loss: 4.132 | Train PPL:  62.281\n",
            "\t Val. Loss: 4.058 |  Val. PPL:  57.865\n",
            "Epoch: 03 | Time: 0m 3s\n",
            "\tTrain Loss: 3.837 | Train PPL:  46.376\n",
            "\t Val. Loss: 3.993 |  Val. PPL:  54.198\n",
            "Epoch: 04 | Time: 0m 3s\n",
            "\tTrain Loss: 3.547 | Train PPL:  34.719\n",
            "\t Val. Loss: 3.672 |  Val. PPL:  39.338\n",
            "Epoch: 05 | Time: 0m 3s\n",
            "\tTrain Loss: 3.304 | Train PPL:  27.228\n",
            "\t Val. Loss: 3.693 |  Val. PPL:  40.170\n",
            "Epoch: 06 | Time: 0m 3s\n",
            "\tTrain Loss: 3.113 | Train PPL:  22.479\n",
            "\t Val. Loss: 3.480 |  Val. PPL:  32.450\n",
            "Epoch: 07 | Time: 0m 3s\n",
            "\tTrain Loss: 2.909 | Train PPL:  18.344\n",
            "\t Val. Loss: 3.529 |  Val. PPL:  34.074\n",
            "Epoch: 08 | Time: 0m 3s\n",
            "\tTrain Loss: 2.759 | Train PPL:  15.783\n",
            "\t Val. Loss: 3.290 |  Val. PPL:  26.832\n",
            "Epoch: 09 | Time: 0m 3s\n",
            "\tTrain Loss: 2.546 | Train PPL:  12.751\n",
            "\t Val. Loss: 3.238 |  Val. PPL:  25.485\n",
            "Epoch: 10 | Time: 0m 3s\n",
            "\tTrain Loss: 2.362 | Train PPL:  10.615\n",
            "\t Val. Loss: 3.149 |  Val. PPL:  23.320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(valid_losses, label = 'valid loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "T1cGTn1D8UlU",
        "outputId": "15bfa6f9-d5b6-4bad-c999-fc73ab199de8"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 127
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mul_model.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(mul_model, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WneacUDZ9b2V",
        "outputId": "8fab3594-b1e7-49e7-c433-6bddb205e57f"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 3.118 | Test PPL:  22.609 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 Additive Attention"
      ],
      "metadata": {
        "id": "olF-9jzM-af8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "emb_dim     = 256  \n",
        "hid_dim     = 512  \n",
        "dropout     = 0.5\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "\n",
        "attn = Attention(hid_dim, variants = 'additive')\n",
        "enc  = Encoder(input_dim,  emb_dim,  hid_dim, dropout)\n",
        "dec  = Decoder(output_dim, emb_dim,  hid_dim, dropout, attn)\n",
        "\n",
        "add_model = Seq2SeqPackedAttention(enc, dec, SRC_PAD_IDX, device).to(device)\n",
        "add_model.apply(initialize_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPpsjWEh9bvh",
        "outputId": "ca047b81-9f17-4abf-e527-d9fd5566d1ab"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqPackedAttention(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(1391, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "      (W): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (U): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(1130, 256)\n",
              "    (gru): GRU(1280, 512)\n",
              "    (fc): Linear(in_features=1792, out_features=1130, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can print the complexity by the number of parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in add_model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "    \n",
        "count_parameters(add_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk7sPmuJ-fAL",
        "outputId": "2b51152a-5c23-4c3f-f5cc-04de37603cef"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "356096\n",
            "393216\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "393216\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "524288\n",
            "   512\n",
            "   512\n",
            "262144\n",
            "   512\n",
            "524288\n",
            "   512\n",
            "289280\n",
            "1966080\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "2024960\n",
            "  1130\n",
            "______\n",
            "9105258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "# training hyperparameters\n",
        "optimizer = optim.Adam(add_model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX) # combining softmax with cross entropy"
      ],
      "metadata": {
        "id": "vWU8k33O-e5X"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for src, src_length, trg in loader:\n",
        "        \n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, attentions = model(src, src_length, trg)\n",
        "        \n",
        "        # trg    = [trg len, batch size]\n",
        "        # output = [trg len, batch size, output dim]\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        # the loss function only works on 2d inputs with 1d targets thus we need to flatten each of them\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg    = trg[1:].view(-1)\n",
        "        # trg    = [(trg len - 1) * batch size]\n",
        "        # output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        # clipping the gradients to prevent them from exploding (a common issue in RNNs)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ],
      "metadata": {
        "id": "ncXQ0yUDAxba"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, criterion, loader_length):\n",
        "        \n",
        "    # turning off dropout (and batch norm if used)\n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for src, src_length, trg in loader:\n",
        "        \n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, attentions = model(src, src_length, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            # trg    = [trg len, batch size]\n",
        "            # output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            # trg    = [(trg len - 1) * batch size]\n",
        "            # output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ],
      "metadata": {
        "id": "VBV3f3LHA9LV"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting everything together"
      ],
      "metadata": {
        "id": "GuR-H1zzBHLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_length = len(list(iter(train_loader)))\n",
        "val_loader_length   = len(list(iter(valid_loader)))\n",
        "test_loader_length  = len(list(iter(test_loader)))"
      ],
      "metadata": {
        "id": "fnonUaCc-eyF"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "zBBrdT_JAzcA"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "num_epochs = 10\n",
        "clip       = 1\n",
        "\n",
        "save_path = f'{add_model.__class__.__name__}.pt'\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(add_model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    valid_loss = evaluate(add_model, valid_loader, criterion, val_loader_length)\n",
        "    \n",
        "    # for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(add_model.state_dict(), save_path)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "    \n",
        "    # lower perplexity is better"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26146fb-2578-4453-9aff-cfe65ab5ed88",
        "id": "NHQW_n84Blwq"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 4s\n",
            "\tTrain Loss: 4.966 | Train PPL: 143.517\n",
            "\t Val. Loss: 4.222 |  Val. PPL:  68.152\n",
            "Epoch: 02 | Time: 0m 4s\n",
            "\tTrain Loss: 4.053 | Train PPL:  57.578\n",
            "\t Val. Loss: 3.894 |  Val. PPL:  49.083\n",
            "Epoch: 03 | Time: 0m 4s\n",
            "\tTrain Loss: 3.656 | Train PPL:  38.702\n",
            "\t Val. Loss: 3.664 |  Val. PPL:  38.999\n",
            "Epoch: 04 | Time: 0m 4s\n",
            "\tTrain Loss: 3.414 | Train PPL:  30.383\n",
            "\t Val. Loss: 3.581 |  Val. PPL:  35.915\n",
            "Epoch: 05 | Time: 0m 4s\n",
            "\tTrain Loss: 3.139 | Train PPL:  23.082\n",
            "\t Val. Loss: 3.417 |  Val. PPL:  30.472\n",
            "Epoch: 06 | Time: 0m 4s\n",
            "\tTrain Loss: 2.855 | Train PPL:  17.369\n",
            "\t Val. Loss: 3.362 |  Val. PPL:  28.850\n",
            "Epoch: 07 | Time: 0m 4s\n",
            "\tTrain Loss: 2.652 | Train PPL:  14.185\n",
            "\t Val. Loss: 3.262 |  Val. PPL:  26.094\n",
            "Epoch: 08 | Time: 0m 4s\n",
            "\tTrain Loss: 2.427 | Train PPL:  11.330\n",
            "\t Val. Loss: 3.099 |  Val. PPL:  22.165\n",
            "Epoch: 09 | Time: 0m 4s\n",
            "\tTrain Loss: 2.192 | Train PPL:   8.954\n",
            "\t Val. Loss: 3.077 |  Val. PPL:  21.688\n",
            "Epoch: 10 | Time: 0m 4s\n",
            "\tTrain Loss: 2.023 | Train PPL:   7.558\n",
            "\t Val. Loss: 3.011 |  Val. PPL:  20.317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(valid_losses, label = 'valid loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "lxM3EFJPAzTK",
        "outputId": "8736136e-8fea-431a-c83b-1a4f1338e988"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add_model.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(add_model, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9lcKmmtBe1m",
        "outputId": "7ca28fe7-dbc1-4288-d00f-3e7955ef473d"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 2.974 | Test PPL:  19.569 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKDcs_VpBeqS",
        "outputId": "49176ef0-47b3-4956-e477-106fb7003932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqPackedAttention(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(1139, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "      (W): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (U): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(947, 256)\n",
              "    (gru): GRU(1280, 512)\n",
              "    (fc): Linear(in_features=1792, out_features=947, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Testing on Some Random News"
      ],
      "metadata": {
        "id": "5cYGYc2mOVTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4QxTcNajONTp",
        "outputId": "4768be03-d2c0-484c-c657-3d4a50047e08"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ও এখন লাঞ্চ করছে।'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mIwsks85OkSF",
        "outputId": "5fd88793-24e3-4661-db81-870ade965e65"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'She is having lunch now.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_text = text_transform[SRC_LANGUAGE](test[0][0]).to(device)\n",
        "src_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_dG1HGGOpFR",
        "outputId": "b3f16726-a905-4760-cfd0-e436d042c0d0"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,  53,  47, 300,  65,   4,   3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trg_text = text_transform[TRG_LANGUAGE](test[0][1]).to(device)\n",
        "trg_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTZRfVo7Oo7b",
        "outputId": "6d1e7bcc-55e9-4e95-ee37-5e87643a29ff"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,  46,  11, 420, 213,  70,   4,   3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_text = src_text.reshape(-1, 1)  # because batch_size is 1"
      ],
      "metadata": {
        "id": "8mS3vKf2Oo1O"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trg_text = trg_text.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "q4zWNUCZOz12"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_text.shape, trg_text.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HphhZpScOzdO",
        "outputId": "cd573df3-213b-489e-b958-9276bdaba964"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([7, 1]), torch.Size([8, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
      ],
      "metadata": {
        "id": "RoWr66bWO594"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output, attentions = model(src_text, text_length, trg_text, 0) # turn off teacher forcing"
      ],
      "metadata": {
        "id": "EHzoQv_GO528"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape # trg_len, batch_size, trg_output_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb02fiyWPAYS",
        "outputId": "de5f875d-4584-4f7b-998f-f8a9e077a97c"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 1, 1130])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = output.squeeze(1)"
      ],
      "metadata": {
        "id": "cicnGTG9PAiF"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH6FZqCoPWCD",
        "outputId": "3887ab68-c132-4f66-f016-7f35879a0090"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 1130])"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = output[1:]\n",
        "output.shape # trg_len, trg_output_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDnIKWGCPdq3",
        "outputId": "18ec81a7-8012-43f3-d1e9-8fe3453c471c"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7, 1130])"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_max = output.argmax(1) # returns max indices"
      ],
      "metadata": {
        "id": "N-RJHPtWPdiw"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0ROFY5HPpcu",
        "outputId": "c824e94f-3ca2-4208-8c40-3a6b051f2ad5"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 23,  14,  27, 239,  70,   4,   3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
      ],
      "metadata": {
        "id": "_LZetMglPrOy"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in output_max:\n",
        "    print(mapping[token.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZg3QPNNPrIX",
        "outputId": "ba734795-8d23-4e86-aa5a-c88d02d4a873"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He\n",
            "'s\n",
            "your\n",
            "daughter\n",
            "now\n",
            ".\n",
            "<eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Attention"
      ],
      "metadata": {
        "id": "L-u2rfbmP2gR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attentions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nQ16ZKXP6Ya",
        "outputId": "a31fab56-bfb9-47c5-be40-812df0b8f0f5"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 1, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](test[0][0]) + ['<eos>']\n",
        "src_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6e_t-40P6lb",
        "outputId": "d3494286-affd-4134-ac9b-e730dc584937"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', 'ও', 'এখন', 'লাঞ্চ', 'করছে', '।', '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
        "trg_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjbeUhQ2QCox",
        "outputId": "ce31a640-3cd6-400d-f216-b7e4834f25a6"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', 'He', \"'s\", 'your', 'daughter', 'now', '.', '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=10)\n",
        "    \n",
        "    y_ticks =  [''] + translation\n",
        "    x_ticks =  [''] + sentence \n",
        "     \n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "7XMzv0OLQCeo"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_attention(src_tokens, trg_tokens, attentions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "6XHm5-I2DcGU",
        "outputId": "2b77b58c-6510-4009-c955-533e28917f35"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-159-b23710e830bc>:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels(x_ticks, rotation=45)\n",
            "<ipython-input-159-b23710e830bc>:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels(y_ticks)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAJXCAYAAADclF3uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgk0lEQVR4nO3de7htB1nf+9+b7AAmAaJcKiAXpYIEkBSCVSBIn4IHqKgFI1iVO5GjB6utStWKHm/VI1ZBsTQgctFWRUAu5eZRyrVqEkrCvfRYLlLu1wRiSMh7/phjw96bvbN3wt7vmGuvz+d58mStMWfmfMdgMed3jTHmWNXdAQCYcMLaAwAAu4fwAADGCA8AYIzwAADGCA8AYIzwAADGCA8AYIzwAADGCA8AYIzwAIBdpKpqzecXHlto7w/F2j8cABw/quqEJOmV/1aK8Ngie38o8sX/Xb5prVlgJ6iq21fV3daeA3aC7r6yqm5QVferqv9UVb+0xhzCY4ssPxS3TPIrVfWnSV5eVTdYey7YRlX1rUn+nyTfXlX3X3se2GZVdcequk+Slye5Y5JvTPI/15hlzxpPypeqqockuXGShyQ5N0kl+ViSi9ecC7ZRVd0zyY8l+dkkFyX511WV7n7pupPBdln2pD8yyWOTvDLJrya5cFl23iozrXyoZ9erqj1J7ppNbPxykvcmeWOS1yb56e7+8xXHg61TVXdO8mtJfqq7z1+W3STJQ5O8eTfHR1XV2sfv2T7L3sH3Jvm77r68qn4kyZXd/TtrzGOPx/pO6u7/VlV36+6Lk6Sq/nGSV4oO2F9V3SrJfZP8YXefv/cE7O7+QFU9K8nDlvfel60557SqunmST3b3xeKDvarq+7OJjf+6z7ITknxrkt9bay7neKxoqc5nVNVJe6Nj8YQkl6w0FmylqrpXkv87yVcluV1V/ZNs9tp2knT3B5P8QZLbV9X91ppz2rJdfjPJv6yqG3R3+0QcVfUTSX4oyUcOuOknk6x6WFJ4rKSq/q8k35vk55ZdX9dZlt8pyYeT/Pqa88E2qap7JPlXSf5Dkuck6ST3S3LPfe5zYne/P8kLk3xrVZ28xqyT9tkuv5bkvyZ5TFV9lfjY3arq65Lct7vvluQ9VXXvqnrUcvMrkvzUcr9VfkYcallBVZ2U5OuSPDzJtavqsUkeVVW/kORlSX4lyeftMoUvvLn+bJKfWQ6vnJDkekn+WZL7L6+dr+vuK6rqekl+Lsm/7+7Prjb0gAO3y7LseknOqapzu/vjXkN2rSuS3LyqfivJ9bP5sMIDquqE7n7acm7hatfzsMdjBd19eTafWPmjJP9uWfzcJI9Jcq3uflcv1pqR7VBV1197hjUt5y48IMlv7o2O7r6yu1+b5CVJrsxmz8ddquq0JL+93PeNqw094GDbJfnC7vMLk/ygwy67T1WdVVV3TPLpJN+T5O+TPLm7H57kXye56RKjV6w4pj0ek6rqEUluleTyJE/M5nj0xctvJv8kybcluXaS4/o3NY5MVZ2V5F9U1Uu7+8VrzzNtWf/vzOb/E7esqpsth1KSJN39uuUN99uTPDDJdZI8pbsvWGXgIUewXV62bJcfrKqndvfH15qVOVX1uGw+2fWWbPaoP7m7/81y2/+Z5IeTnL0Nv9Da4zGkqs5J8oNJ3pXk5knemuSyJTp+PMlvJPlX3f2JFcdkSyy70X8qyQuSfG1VPWDlkUYt6/8z2RyPviDJHZI8sKq+ep/7nNDdr8nm2gQfTPLL3f03a8w75Wpsl/+S5O1Jzt7nisgcp6rqa7OJjgckOSeb145/s1yh9KZJzk7ykO5++4pjfoEfyGNsn92cZyT5xe7+g+7+wSR/nOTZy+0fT/K93X3RSmOyRZZPKTw+yRO6+5XZ/Kx8Q1V9x5pzTdln/f/t8pHyl2bzW9xts3kj/erkC1f6vW6SRyd5eXd/eJ2JZ1yD7XJ2Nue+XLnOxAy6IsknuvuD3X15d78hyfOS3Kq7/3eSB3T3W9Yd8YuEx7H3Nft8fYd9vv6NJO9bTuV4Rne/c3guttBynYqHJvmVfc5p+FCSZya57fEeH4dY/w8n+dMkb84X32RPrqpTkjwpyRO35Te5Y+Uabpd/391vXW1ojrmquk1VXb+735fkw1X13H1u/ookt16+3qrD987xOIaW42p3qarHJPn9bP72yseSPCObE+Jut5wQ96ltOO7GuqrqzGwujvXJbD7VtGfvSWDd/ZGqemaSh1fVd3b3C9eb9Ng4zPp/rDZ/vyjZ7D18TJI7Z3NOx/krjDvGduFgquqHs9mrdcHyaabHJvnPVfWqJK9O8s+X21f/a7QHcsn0Y2Q5kfSHkjyou9+7LLttkmcleUc2ez8e5jcSki+cMPiEbH4+Tk9yUjZ/zOkv933RqKprZXPdhld3939bY9Zj4Wqs/55sjmGfkOSFy296xy3bhYOpzQXyfjKbk6r/XZIbd/cDl9sels2hl/O3dU+6PR5H2XIi1wnZ/P2VX03SVfVj2fzxt//U3d+81Om1u/vAK8qxCy3H7n80y98eqaq7Z/NJjfsut/9lNr8kXJnkxGyi9Y9WGfYYuJrrf+0k35LNeQ7H9Zur7cKB9n6cPMllSX43yYOz+QTLty+33zXJs7dtD8eBnONx9J2+7AZ9WTZ/+O23s7nWwI8neVBV3bS7Py06vqiqvqZ2wVUmD6aq/mE2by6/uLy5VHe/PsmLsvmt5b5J/uk+Jwz+TpIndfe715r5aLoG6//kJL/d3e9ZbegBtsuR2YWvHbdb/n1xkv+Y5FHd/W3d/bmqenQ2e9lPWW26I2SPx1FUVY9M8uiqund3v7iq7pbNCaSfrar7ZLO9/Q2WfSy/1f1wkv9eVU/p7k+tO9Gc5dot35vNyYHv2Pe23vzhwGTz8bj7LYdYHprNiZTHxbH73b7+h2K7HJnd9tqxz/vLfbr7vKp6fJJHVNWDktwsycOSPLy7t/49xjkeR8He3V9V9dNJ3nrgiX/LSUCPTfJ9PjL7Rcs1CR6f5BezqfS7Jnlqd3961cEG7LPuv5Tk5CTfnM2huPfsc58Tk9wxmysQfjjJy7b1mO3VtdvX/1BslyOzm147Dnh/eUt3v2hZfq1sAvQ7k3wiyX/s7retOOoRs8fjKFh+KL4uyX2yubBPki9c1OV9Sd6WzRXj3nGIh9h1lpPmfiqba1Xs/TsT103y2NpcbfG4ewHZ68B1X67lcmo2Vyn9w+5+b23+4Nnnq+pvs/m7JE9aPla74+329T8U2+XI7LbXjkO9vyS5eXc/L5vrdewozvH4MtXGSUl+IpuPyb6pqm5fVS/K5tMHN+vuV4mOL6qqa2dzsu2Te/+/M/GibHYtP3Y5Afe4c7B1X67l8uJsdq1/X1V97fLmcr1sjt0/+3h5c9nt638otsuR2W2vHYd5f/mxqrrFEqg7ivD4Mi0vDpcnuW6Smyb5i2z+6uyF2VS5M8wP0N2XJfmtbK5jctPe58qKywvIO5P80PH0ArLXYdb9JdlcifLBVXV6NieP/XYfR5cB3+3rfyi2y5HZba8dh3l/eXySv9v2T7AcjHM8joLaXJ/jomyuIviHSf58+WHhKlTV12fzOfRndfcHl2V7j2eenc2u5GfsxP9jHc5h1v2BSW6TzWXA37TimMfMbl//Q7Fdjsxueu04Ht9fhMdRshT2Fd392X2W1fHwg38sHeIF5LrZ/Fb3SzvlZKlr4irW/enZXI/hXWvOd6zt9vU/FNvlyOym147j7f1FeLC6fV5AnrwsekqS3+1d8PHA3bzuifU/FNvlyNhOO5PwYCtU1W2SPCjJ7bM5U/+8lUcas5vXPbH+h2K7HBnbaecRHmyNqrpZkpP6OLkq59Wxm9c9sf6HYrscGdtpZxEeAMAYH6cFAMYIDwBgjPBYSVWds/YM28T22J/tsT/bY3+2x/5sj/1t+/YQHuvZ6h+MFdge+7M99md77M/22J/tsb+t3h7CAwAYs+s+1VJVu2uFAWAdH+3uGx240B4PAOBYeM/BFgoPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGDMWHhU1bWq6pSj9FinVNVJR+OxAIA5xzw8qup2VfUbSd6Z5DbLsl+tqrdV1UVV9cRl2a2q6i+XZX9RVbdYlp9dVW+pqgur6jXLw94myf+oqidW1e2O9ToAAEdHdffRf9DNno3vSfKoZdHvJ/mT7r64qm6Q5A1JvqG7u6pO6+5PVtWLk/xpdz+rqh6Z5Du6+7uq6s1J7tvd79973+U5rpvkwUkekaST/N7yHJ85zGxHf4UBgANd0N1nHrjwWIXHp5NclOTR3f2OA27bk+SC5Z+XJHlJd3+uqj6a5CbdfflyGOUD3X3Dqnpqklsn+ZMkz+/ujx3k+W6XTXjcobuvd5Dbz0lyzvLtXY7aigIAh3LQ8DhWh1q+O8n7kzy/qp5QVbfce0N3X5Hkm5L8aZJvT/Lyq3qg7n5skn+b5OZJLlj2mCT5wuGZn0vygiTvW573YI9xbnefebANAADM2XMsHrS7X5nklUskfH+SFy57NB6d5KNJTu7ul1bV65P87fKfvSHJQ5I8J8n3JXltklTVrbv7r5P8dVXdL8nNl8MsT09yw2wO49z9YHtCAIDtckwOtRz0iaq+KckHklyR5IVJrpOkkjxxOa/jltlExA2TfCTJI7r7vVX1/CRfv9z3L5L8aJKvyeawzN9cgzmc4wEAx97cOR7bTHgAwIjRczwAAL6E8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxuxZewCAnaPWHmCrfOqzn1l7hK1y49NusPYIW+Wyz1160OX2eAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBm68Ojqi454PuHV9XvrDUPAHDNbX14AADHjx0dHlV1o6p6XlWdt/xz97VnAgAObc/aAxyBr6iqN+3z/VcledHy9ZOS/GZ3v66qbpHkFUluNzwfAHCEdkJ4XNrdZ+z9pqoenuTM5dt7Jzm9qvbefL2qOrW7Dzwv5Jwk5xz7UQGAq7ITwuOqnJDkm7v776/qTt19bpJzk6SqemIwAOBL7ehzPJK8Msnj9n5TVWesNwoAcDg7PTx+JMmZVXVRVb0tyWPXHggAOLTq3l1HHhxqAa65OvxddpFPffYza4+wVW582g3WHmGrXPa5Sy/o7jMPXL7T93gAADuI8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxuxZe4BpJ5xwYk495bS1x9gat/2Gf7z2CFvl/PNfvvYIW+WJz3nu2iNslZ9+5PevPcJWOe2UU9ceYat099oj7Aj2eAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBmx4ZHVb177RkAgKtnx4YHALDz7OTw+EiSVNVNquo1VfWmqnpLVZ219mAAwMHtWXuAa6q777p8+S+SvKK7f7mqTkxy8opjAQBXYceGxz7OS/KMqjopyZ9195sOvENVnZPknM3XO3knDwDsbDv+Xbi7X5Pknknen+SZVfXQg9zn3O4+s7vPrKrxGQGAjR0fHlV1yyQf6u6nJXl6kjuvPBIAcAjHw6GWeyX5iaq6PMklSb5kjwcAsB12fHh097OSPGvtOQCAw9vxh1oAgJ1DeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY4QHADBGeAAAY6q7155hVFXtrhWGL8PHL7lk7RG2ys1udJO1R9gql1568dojsN0u6O4zD1xojwcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMOa4C4+qOnHtGQCAg1s1PKrqF6rqR/f5/per6l9W1a9X1Vuq6s1V9eDltntV1Uv2ue/vVNXDl6/fXVW/VlVvTHL28GoAAEdo7T0ez0jy0CSpqhOSPCTJ3yU5I8mdktw7ya9X1U2O4LE+1t137u4/OkazAgBfpj1rPnl3v7uqPlZV/yjJP0jy35PcI8l/7u7PJ/lQVb06yV2TfPowD/fHh7qhqs5Jcs5RGhsAuIZWDY/F05M8PMlXZ7MH5D6HuN8V2X8PzXUOuP0zh3qC7j43yblJUlV9TQcFAL48ax9qSZIXJLlvNns1XpHktUkeXFUnVtWNktwzyd8keU+S06vq2lV1WpJ/utK8AMA1tPoej+7+XFW9Ksknu/vzVfWCJN+S5MIkneQnu/uDSVJVf5LkLUn+VzaHZQCAHaS61z3ysJxU+sYkZ3f3uwaez6EWOEIfv+SStUfYKje70ZGc5757XHrpxWuPwHa7oLvPPHDh2h+nPT3J/0zyFxPRAQCsa+1PtbwtydetOQMAMGcbTi4FAHYJ4QEAjBEeAMAY4QEAjBEeAMAY4QEAjBEeAMAY4QEAjBEeAMAY4QEAjBEeAMAY4QEAjBEeAMAY4QEAjBEeAMAY4QEAjBEeAMAY4QEAjBEeAMAY4QEAjBEeAMAY4QEAjBEeAMAY4QEAjBEeAMAY4QEAjNmz9gDA9vrKU05Ze4StcumlF689Aux49ngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAwRngAAGOEBwAw5mqHR1X9fFX9+NEcoqreXVU3PMjye1XV3Y7mcwEA69n2PR73SnK1wqOq9hybUQCAL9cRhUdV/UxV/Y+qel2S2y7LHlNV51XVhVX1vKo6eVn+zKr67n3+20uWf59QVb9bVe+oqj+vqpfue78kj6uqN1bVm6vqG6rqVkkem+THqupNVXVWVd1oea7zln/uvjz2z1fVc6rq9UmeczQ2DABw9B02PKrqLkkekuSMJPdPctflpud39127+05J3p7kUYd5qAcmuVWS05P8QJJvOeD2j3b3nZP8hyQ/3t3vTvLUJL/Z3Wd092uTPGn5/q5JHpTk6fv896cnuXd3f+9B1uGcqjq/qs4/3PoCAMfOkRyWOCvJC7r7s0lSVS9alt+hqn4pyWlJTk3yisM8zj2SPLe7r0zywap61QG3P3/59wXZRMrB3DvJ6VW19/vrVdWpy9cv6u5LD/Yfdfe5Sc5d5u/DzAkAHCNfzvkQz0zyXd19YVU9PJvzMZLkiix7UqrqhCTXOsLHu2z59+evYq4Tknxzd//9vguXEPnMET4PALCSIznH4zVJvquqvqKqrpvkAcvy6yb5QFWdlOT79rn/u5PcZfn6O5KctHz9+iQPWs71+Af5YqhclYuX59nrlUket/ebqjrjCB4DANgShw2P7n5jkj9OcmGSlyU5b7npZ5P8dTZB8Y59/pOnJfnWqrowm/M49u6JeF6Sv0vytiR/kOSNST51mKd/cZJ/vvfk0iQ/kuTMqrqoqt6WzcmnAMAOUd1zpzxU1andfUlV3SDJ3yS5e3d/cGyAOMcDro7J14edYJ/zy4DDu6C7zzxw4fQ1L15SVadlc97HL05HBwCwrtHw6O57TT4fALBdtv3KpQDAcUR4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABj9qw9ALC9qmrtEdhi17nOqWuPsFU+9PEPrz3CVrn+yScfdLk9HgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIwRHgDAGOEBAIzZivCoqltV1dur6mlV9daqemVVfUVVnVFVf1VVF1XVC6rqK6vqxlV1wfLf3amquqpusXz//1XVyeuuDQBwKFsRHouvT/KU7r59kk8meVCSZyd5fHd/Y5I3J/m57v5wkutU1fWSnJXk/CRnVdUtk3y4uz974ANX1TlVdX5VnT+0LgDAQexZe4B9/K/uftPy9QVJbp3ktO5+9bLsWUmeu3z9hiR3T3LPJL+S5L5JKslrD/bA3X1uknOTpKr6WAwPABzeNu3xuGyfrz+f5LSruO9rstnbccskL0xypyT3yCHCAwDYDtsUHgf6VJJPVNVZy/c/kGTv3o/XJvn+JO/q7iuTfDzJ/ZO8bnxKAOCIbdOhloN5WJKnLieM/m2SRyRJd7+7qiqbPR/JJji+prs/sc6YAMCRqO7ddcqDczwAjo7rXOfUtUfYKh/6+IfXHmGrXP/kky/o7jMPXL7Nh1oAgOOM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxggPAGCM8AAAxuxZewAAdqbLLvvs2iNslVOufe21R9gR7PEAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMYIDwBgjPAAAMbsWXuACVV1TpJz1p4DAHa76u61ZxhVVbtrhQGOkSo7zfd1+RWXrz3CVtlz4okXdPeZBy73UwMAjBEeAMCY4yo8quqlVXXTtecAAA7uuDq5tLvvv/YMAMChHVd7PACA7SY8AIAxwgMAGCM8AIAxwgMAGCM8AIAxwgMAGCM8AIAxwgMAGCM8AIAxwgMAGCM8AIAxwgMAGCM8AIAxwgMAGCM8AIAxwgMAGCM8AIAxwgMAGCM8AIAxwgMAGCM8AIAxwgMAGCM8AIAxwgMAGCM8AIAxwgMAGCM8AIAxe9YeAICdqfvKtUfYKiee4Hf5I2ErAQBjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjhAcAMEZ4AABjRsKjqq5VVaccxce7flWJJgDYYY7pm3dV3a6qfiPJO5PcZll2l6p6dVVdUFWvqKqbLMvPqKq/qqqLquoFVfWVy/Ifqaq3Lcv/aHnoeyR5Z1X9fFXd4liuAwBw9FR3H90H3OzZ+J4kj1oW/X6SP+nui6vqpCSvTvKd3f2Rqnpwkv+jux9ZVRcleVx3v7qqfiHJ9br7R6vqfyf52u6+rKpO6+5PLs9zwyQ/kORhST6Y5PeSvLC7P3eQmc5Jcs7y7V2O6goDQJKj/X6601XVBd195pcsPwbh8ekkFyV5dHe/44Db7pDkDUn+dll0YpIPJDk7yZu7+xbL/W6d5LndfeeqenmSS5L8WZI/6+5LDvKc35LkGUku7+5vPMx8fjIAOOqEx/4OFR7H4lDLdyd5f5LnV9UTquqW+86R5K3dfcbyzx27+9sO83j/LMlTktw5yXlVtecLD1Z1elX9epJnJ3l9kscc1TUBAI6qox4e3f3K7n5wkrOSfCrJC6vq/62qW2VzrseNlj0UqaqTqur23f2pJJ+oqrOWh/mBJK9eTiC9eXe/Ksnjk1w/yalVdeeq+qskT0/yjiT/qLsf3d1/fbTXBwA4eo76oZaDPknVNyX5QHe/r6rOSPLkbCJiT5Lf6u6nLcufmuTkbA7FPCKbQyyvWu5bSf6gu3+1qm6XJN399mswi31hABx1DrXsb+wcj20nPAA4Fnbb++nhTJ7jAQBwUMIDABgjPACAMcIDABgjPACAMcIDABgjPACAMcIDABgjPACAMcIDABgjPACAMcIDABgjPACAMcIDABgjPACAMcIDABgjPACAMcIDABgjPACAMcIDABgjPACAMcIDABgjPACAMcIDABgjPACAMcIDABgjPACAMcIDABizZ+0BVvDRJO9Ze4gkN8xmFjZsj/3ZHvuzPfZne+xvK7ZHVa09wl5bsT2S3PJgC6u7pwchSVWd391nrj3HtrA99md77M/22J/tsT/bY3/bvj0cagEAxggPAGCM8FjPuWsPsGVsj/3ZHvuzPfZne+zP9tjfVm8P53gAAGPs8QAAxggPAGCM8AAAxggPAGCM8AAAxvz/9U6QYJMWAPYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sUOvPAuXDjlz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}